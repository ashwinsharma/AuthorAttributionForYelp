{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    },
    "colab": {
      "name": "RNN_GRU_predictions.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tNQFoAPT3ASz",
        "colab_type": "text"
      },
      "source": [
        "This notebook can be used to predict a single test review against the each of the GRU-RNN models created per author in the RNN-GRU.ipynb notebook. The preprocessing and prediction code is identical to the aforementioned notebook. The test review can be selected below."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uh162QQZ3teP",
        "colab_type": "code",
        "outputId": "737e8cb1-19a8-4957-90dd-1c71aa50beb1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 425
        }
      },
      "source": [
        "!pip install pickle\n",
        "!pip install numpy\n",
        "!pip install tensorflow==1.15.0"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[31mERROR: Could not find a version that satisfies the requirement pickle (from versions: none)\u001b[0m\n",
            "\u001b[31mERROR: No matching distribution found for pickle\u001b[0m\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (1.17.4)\n",
            "Requirement already satisfied: tensorflow==1.15.0 in /usr/local/lib/python3.6/dist-packages (1.15.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.0) (0.1.8)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.0) (3.1.0)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.0) (0.8.0)\n",
            "Requirement already satisfied: numpy<2.0,>=1.16.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.0) (1.17.4)\n",
            "Requirement already satisfied: keras-applications>=1.0.8 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.0) (1.0.8)\n",
            "Requirement already satisfied: tensorboard<1.16.0,>=1.15.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.0) (1.15.0)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.0) (1.12.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.0) (1.1.0)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.0) (1.11.2)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.0) (0.8.1)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.0) (0.33.6)\n",
            "Requirement already satisfied: tensorflow-estimator==1.15.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.0) (1.15.1)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.0) (1.1.0)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.0) (1.15.0)\n",
            "Requirement already satisfied: gast==0.2.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.0) (0.2.2)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.0) (3.10.0)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.8->tensorflow==1.15.0) (2.8.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.0) (3.1.1)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.0) (0.16.0)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.0) (42.0.2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_JKAyQDC4sX_",
        "colab_type": "code",
        "outputId": "c9124ae2-d44a-4846-e286-cfc19db903bb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 63
        }
      },
      "source": [
        "import pickle\n",
        "import numpy as np\n",
        "from tensorflow import keras"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ToSdkA1Q3zEH",
        "colab_type": "code",
        "outputId": "7f16ce34-6190-4564-ba87-1589375e476a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "data_dir = 'gdrive/My Drive/Colab Notebooks/AuthorshipAttribution/data' # @param {type:\"string\"}\n",
        "model_dir = 'gdrive/My Drive/Colab Notebooks/AuthorshipAttribution/models/gru_models' # @param {type:\"string\"}"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S-PPPX3F3teU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_data = data_dir + \"/test_data.pickle\"\n",
        "with open(test_data, \"rb\") as f:\n",
        "    test_data = pickle.load(f)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J1VoVlCi3teX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_test = test_data['test_texts']\n",
        "y_test = test_data['test_labels']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9hhkdxzn3teZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_chunks(l, n):\n",
        "    n = max(1, n)\n",
        "    return [l[i:i+n] for i in range(0, len(l), n)]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V9ycNtxj3teb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 182 words is quite short\n",
        "# Try to join 5 tests texts together\n",
        "longer_test_texts = get_chunks(x_test, 5)\n",
        "longer_test_labels = get_chunks(y_test, 5)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pSOdfafS3tee",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "longer_test_texts = ['\\n'.join(chunk) for chunk in longer_test_texts]\n",
        "longer_test_labels = [chunk[0] for chunk in longer_test_labels]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "joAEd5F73teg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "author_models = []\n",
        "for i in range(50):\n",
        "    author_models.append((keras.models.load_model(model_dir + \"/author\"+str(i)+\".h5\"), i))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TDNto8kb3tei",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# vectorization - chars to ints\n",
        "import string\n",
        "import random\n",
        "import sys\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "from tensorflow import keras\n",
        "# keras.models import load_model\n",
        "\n",
        "def sample(preds, temperature=1.0):\n",
        "    \"\"\"Sample predictions from a probability array\"\"\"\n",
        "    preds = np.asarray(preds).astype('float64')\n",
        "    preds = np.log(preds + 1e-6) / temperature\n",
        "    exp_preds = np.exp(preds)\n",
        "    preds = exp_preds / np.sum(exp_preds)\n",
        "    probas = np.random.multinomial(1, preds, 1)\n",
        "    return np.argmax(probas)\n",
        "\n",
        "def generate(model, diversity=0.5, text=\"\"):\n",
        "    \"\"\"Generate text from a model\"\"\"\n",
        "    start_index = random.randint(0, len(text) - maxlen - 1)\n",
        "    generated = ''\n",
        "    sentence = text[start_index: start_index + maxlen]\n",
        "    generated += sentence\n",
        "    print('----- Generating with seed: \"' + sentence + '\"')\n",
        "    sys.stdout.write(generated)\n",
        "\n",
        "    for i in range(5000):\n",
        "        x = np.zeros((1, maxlen), dtype=np.int)\n",
        "        for t, char in enumerate(sentence):\n",
        "            try:\n",
        "                x[0, t] = char_indices[char]\n",
        "            except:\n",
        "                print(sentence)\n",
        "        preds = model.predict(x, verbose=0)[0][0]\n",
        "        next_index = sample(preds, diversity)\n",
        "        next_char = indices_char[next_index]\n",
        "        generated += next_char\n",
        "        sentence = sentence[1:] + next_char\n",
        "        sys.stdout.write(next_char)\n",
        "        sys.stdout.flush()\n",
        "    return\n",
        "\n",
        "def vectorize(text):\n",
        "    \"\"\"Convert text into character sequences\"\"\"\n",
        "    step = 3\n",
        "    sentences = []\n",
        "    next_chars = []\n",
        "    for i in range(0, len(text) - maxlen, step):\n",
        "        sentences.append(text[i: i + maxlen])\n",
        "        next_chars.append(text[i + maxlen])\n",
        "    X = np.zeros((len(sentences), maxlen), dtype=np.int)\n",
        "    y = np.zeros((len(sentences), len(chars)), dtype=np.bool)\n",
        "    for i, sentence in enumerate(sentences):\n",
        "        for t, char in enumerate(sentence):\n",
        "            X[i, t] = char_indices[char]\n",
        "        y[i, char_indices[next_chars[i]]] = 1\n",
        "    return X, y\n",
        "\n",
        "def clean_text(text, charset):\n",
        "    text = \" \".join(text.split())  # all white space is one space\n",
        "    text = \"\".join([x for x in text if x in charset])  # remove characters that we don't care about\n",
        "    return text\n",
        "\n",
        "def get_model(modelfile, freeze=False):\n",
        "    model = keras.models.load_model(modelfile)\n",
        "    if freeze:\n",
        "        for layer in model.layers[:6]:\n",
        "            layer.trainable = False\n",
        "    return model\n",
        "\n",
        "chars = \" \" + string.ascii_letters + string.punctuation  # sorted to keep indices consistent\n",
        "charset = set(chars)  # for lookup\n",
        "char_indices = dict((c, i) for i, c in enumerate(chars))\n",
        "indices_char = dict((i, c) for i, c in enumerate(chars))\n",
        "\n",
        "maxlen = 100  # must match length which generated model - the sequence length\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VLqeGhg-3mnj",
        "colab_type": "text"
      },
      "source": [
        "Select the test review here. Enter any number between 0 and 499."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dIn9p0dCNQdc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Edit this to predict for a candidate review in the corresponding index between 0 and 499\n",
        "test_review_index =   100# @param {type:\"integer\"}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cqclsGTl3tek",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# indicies = list(range(len(longer)))\n",
        "test_texts = np.array(longer_test_texts)\n",
        "test_labels = np.array(longer_test_labels)\n",
        "\n",
        "text = test_texts[test_review_index]\n",
        "label = test_labels[test_review_index]\n",
        "X, y = vectorize(clean_text(text, charset))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xwhDs7fF3tem",
        "colab_type": "code",
        "outputId": "af4477bd-e35b-4a2a-cbf8-25dbba2695eb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from datetime import datetime\n",
        "predictions = []\n",
        "losses = []\n",
        "t1 = datetime.now()\n",
        "for am in author_models:\n",
        "    print(\".\", end=\"\")\n",
        "    model = am[0]\n",
        "    label = am[1]\n",
        "    loss = model.evaluate(X, y, verbose=0)\n",
        "    losses.append((loss, label))\n",
        "print(\" {}\".format(datetime.now() - t1))\n",
        "predictions.append(losses)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            ".................................................. 0:04:51.856830\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3jzVxTVU3tep",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pred_is = []\n",
        "for pred in predictions:\n",
        "    pred_i = [p[0] for p in pred]\n",
        "    pred_is.append(pred_i)\n",
        "pred = [np.argmin(pred) for pred in pred_is]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3O2cY5a64MY4",
        "colab_type": "text"
      },
      "source": [
        "See the predicted author id and actual author id below."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_6M9s1Tq3ter",
        "colab_type": "code",
        "outputId": "2799701e-9b8e-4e46-fe4f-ba3d755267a4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#predicted author id\n",
        "pred"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[10]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O8GYla_Q3tet",
        "colab_type": "code",
        "outputId": "3d9aaff4-2fd6-447d-a8d0-5c7a9ce65797",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#actual author id\n",
        "test_labels[test_review_index]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "10"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    }
  ]
}